# 计算

## 图灵自动机

## 冯·诺依曼结构计算机

## 可计算性

## 计算复杂性

### Kolmogorov复杂度

#### 定义

对于一个通用计算机u，二院字符串x的Kolmogorov复杂度$K_\mathcal{u}(x)$定义为
$$
K_{\mathcal{U}}(x)=\min _{p: U(p)=x} l(p)
$$
即能够输出x并停止所有的程序的最小长度，一定程度上反应了字符串x的信息内容、冗余度、结构化程度。

#### 通用性

对于其他计算机A，虽所有二元串均有
$$
K_{\mathcal{U}}(x) \leq K_{\mathcal{A}}(x)+c_{\mathcal{A}}
$$

#### 条件复杂度定理

条件复杂度小于序列的长度
$$
K(x|l(x)) \le l(s)+c
$$

#### 复杂度的上界和下界

上界
$$
K(x) \leq K(x \mid l(x))+2 \log l(x)+c
$$
下界
$$
\begin{gathered}
\text { 复杂度 } K(x)<k \text { 的二进字符串 } x \text { 的数目满足 } \\
\left|\left\{x \in\{0,1\}^{*}: K(x)<k\right\}\right|<2^{k}
\end{gathered}
$$

## 贝叶斯学习

### 贝叶斯学习概念

#### 学习任务

给定数据D，确定假设空间H中的**最佳假设**

#### 最佳假设

在给定数据D以及H中不同假设的先验概率的有关知识下，最可能的假设

### 贝叶斯法则

#### 贝叶斯公式

$$
P(h \mid D)=\frac{P(D \mid h) P(h)}{P(D)}
$$

$P(h)$：先验概率

$P(h|D)$：后验概率

#### 全概率公式

全概率公式: 如果事件 $A A_{1}, A_{2}, \cdots A_{n}$ 互斥，且满足 $\sum_{i=1}^{n} P\left(A_{i}\right)=1$ ，则
$$
P(B)=\sum_{i=1}^{n} P\left(B \mid A_{i}\right) P\left(A_{i}\right)
$$

### MAP 和 ML

#### 最大后验（MAP）决策规则

$$
\begin{aligned}
h_{\mathrm{MAP}} &=\underset{h \in H}{\arg \max } P(h \mid D) \\
&=\underset{h \in H}{\arg \max } P(D \mid h) P(h)
\end{aligned} \\
$$

一般用**第二个式子简单**

#### 最大似然（ML）决策规则

$$
h_{\mathrm{ML}}=\underset{h \in H}{\arg \max } P(D \mid h)
$$

### 贝叶斯最优分类器
$$
v^{*}=\underset{v_{j} \in V}{\arg \max } \sum_{h_{i} \in H} P\left(v_{j} \mid h_{i}\right) P\left(h_{i} \mid D\right)
$$
例子：

考虑一个包含三个假设 $h_{1}, h_{2}, h_{3}$ 的假设空间。
给定训练数据 $D$ 时三个假设的后验概率分别是 $0.4$,
$0.3,0.3$ ，因此 $h_{1}$ 为 $\mathrm{MAP}$ 假设。
已知一新实例x在不同假设下的分类结果: 被 $h_{1}$ 分
类为正，被 $h_{2}$ 和 $h_{3}$ 分类为反。

新实例的可能分类集合为 $V=\{+,-\}$
- $P\left(h_{1} \mid D\right)=0.4, P\left(-\mid h_{1}\right)=0, P\left(+\mid h_{1}\right)=1$
- $P\left(h_{2} \mid D\right)=0.3, P\left(-\mid h_{2}\right)=1, P\left(+\mid h_{2}\right)=0$
- $P\left(h_{3} \mid D\right)=0.3, P\left(-\mid h_{3}\right)=1, P\left(+\mid h_{2}\right)=0$
- $\sum_{h_{i} \in H} P\left(+\mid h_{i}\right) P\left(h_{i} \mid D\right)=0.4 ; \sum_{h_{i} \in H} P\left(-\mid h_{i}\right) P\left(h_{i} \mid D\right)=0.6$

所以选第二个

### 朴素贝叶斯分类

#### 适用场景

每个实例𝑥𝑥可由若干属性描述， $x =  \langle a_1, a_2, ... ,aaaaa_n \rangle$

目标分类函数$f(x)$在某有限集合V中取值

#### 决策规则

$$
\begin{aligned}
&v_{\text {MAP }}=\underset{v_{j} \in V}{\arg \max } P\left(v_{j} \mid a_{1}, a_{2}, \cdots, a_{n}\right) \\
&=\underset{v_{j} \in V}{\arg \max } P\left(v_{j} \mid a_{1}, a_{2}, \cdots, a_{n}\right) P\left(a_{1}, a_{2}, \cdots, a_{n}\right) \\
&=\underset{v_{j} \in V}{\arg \max } P\left(a_{1}, a_{2}, \cdots, a_{n} \mid v_{j}\right) P\left(v_{j}\right)
\end{aligned}
$$

一般用最后一个式子。

若属性值之间相互独立则
$$
P\left(a_{1}, a_{2}, \cdots, a_{n} \mid v_{j}\right)=\prod_{i} P\left(a_{i} \mid v_{j}\right)\\
v_{\mathrm{NB}}=\underset{v_{j} \in V}{\arg \max } P\left(v_{j}\right) \prod_{i} P\left(a_{i} \mid v_{j}\right)
$$

#### 例子 打网球

属性：Outlook、Temperature、 Humidity和Wind来描述 

判断某个周六是否适合打网球（Yes or No）

给了多天的属性值以及是否打网球的结果
$$
\begin{aligned}
v_{\mathrm{NB}}=& \underset{v_{j} \in V}{\arg \max } P\left(v_{j}\right) \\
& * P\left(\text { Outlook }=\text { Sunny } \mid v_{j}\right) P\left(\text { Temperature }=\text { Cool } \mid v_{j}\right) \\
& * P\left(\text { Humidity }=\text { High } \mid v_{j}\right) P\left(\text { Wìnd }=\text { Strong } \mid v_{j}\right)
\end{aligned}
$$
计算结果:
$$
\begin{aligned}
&P(\text { PlayTennis }=\text { Yes })=9 / 14=0.64 ; \\
&P(\text { PlayTennis }=\text { No })=5 / 14=0.36 \\
&P(\text { Wind }=\text { Strong } \mid \text { PlayTennis }=\text { Yes })=3 / 9=0.33 \\
&P(\text { Wind }=\text { Strong } \mid \text { PlayTennis }=\text { No })=3 / 5=0.60 \ldots \ldots . \\
&P(\text { Yes }) P(\text { Sunny } \mid \text { Yes }) P(\text { Cool } \mid \text { Yes }) P(\text { High } \mid \text { Yes }) P(\text { Strong } \mid \text { Yes })=0.0053 \\
&P(\text { No }) P(\text { Sunny } \mid \text { No }) P(\text { Cool } \mid \text { No }) P(\text { High } \mid \text { No }) P(\text { Strong } \mid \text { No })=0.02
\end{aligned}
$$
结论：NO

## 决策树学习

以打网球为例子

#### 构造决策树

**核心问题：**哪个属性是最佳的分类属性



